<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis深入学习之过期策略]]></title>
    <url>%2F2019%2F01%2F26%2Fredis%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[Redis过期策略 前言​ 我们都知道Redis是一个键值对内存数据库，我们设置键值对时，可以对键值对设置超时时间。所以那些过期了的键值对就需要一种清理策略来清理。需要清理的场景主要有两种，一种是Redis那些设置了超时时间并且已经超时的键值对，此时的键值对失效了需要被清理，这种场景会采用定时删除+惰性删除的策略来清理。另外一种是由于Redis配置的内存已经到达上限，需要对那些过期或者还没过期的键值对按照内存淘汰策略进行清理，释放部分内存。 ​ Redis之所以要采用这几种过期策略。主要因为 Redis 是单线程的，清理键值对的时间也会占用线程的处理时间，如果清理的太过于繁忙，将会导致线上读写指令出现卡顿。 定时删除​ redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。 从过期字典中随机 20 个 key； 删除这 20 个 key 中已经过期的 key； 如果过期的 key 比率超过 1/4，那就重复步骤 1； 同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。 从库的过期策略​ 这里从库需要特别说明下，从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。 惰性删除​ 看了上面定时删除。肯定就会知道，定时删除会存在一个问题，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？ ​ 这就要用到惰性删除了。这就是说，在你获取某个 key 的时候，Redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 内存淘汰机制​ Redis经过上面的定时删除以及惰性删除还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？可能会存在大量过期 key 堆积在内存里，将会导致 redis 内存块耗尽 ​ 这里说明下，在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。针对上面的内存耗尽的问题，当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。 noeviction 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。 volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。 volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。 volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。 allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰（这种事最常用的）。 allkeys-random 跟上面一样，不过淘汰的策略是随机的 key。 volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。 总结​ Redis过期策略有三种，定时删除部分过期数据、惰性删除部分再次被访问的过期数据、基于内存淘汰策略淘汰部分数据。了解了Redis过期策略，有助于我们更好的理解Redis。]]></content>
      <categories>
        <category>Redis 教程</category>
      </categories>
      <tags>
        <tag>微缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis深入学习之数据持久化]]></title>
    <url>%2F2019%2F01%2F26%2Fredis%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis数据持久化 前言​ Redis 的数据全部在内存里，之所以需要持久化在硬盘是为了在之后能重用数据，或者是为了防止系统故障、宕机导致内存中的数据全部丢失。另外，存储在Redis中的数据有可能是经过长时间计算得出的，或者有程序正在使用Redis存储的数据进行计算，所以用户会希望自己可以将这些数据存储起来以便之后使用，不需要重新计算了。 ​ Redis提供了两种不同的持久化方法来将数据存储到硬盘里面。一种方法叫快照（RDB），他可以将存在于某一时刻的数据都写入硬盘里面。另外一种方法叫做只追加文件（AOF）,他会在执行写命令时，将被执行的命令写入硬盘里面。这两种持久化方法既可以同时使用，又可以单独使用，在某些情况下甚至两种方法都不使用，具体选择哪种持久化方法需要根据用户的数据以及应用来决定。 快照持久化概念​ Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。在创建快照之后，用户可以对快照进行备份，可以讲快照复制到其他服务器从而创建具有相同数据的服务器副本，还可以将快照留在原地以便重启服务器时使用。 创建快照(RDB)的方法 客户端可以通过向Redis发送BGSAVE命令来创建一个快照。对于支持BGSAVE命令的平台来说（基本所有的平台都只支持，除了windows平台），Redis会调用fork来创建一个子进程，然后子进程负责将快照写入磁盘，而父进程则继续处理命令请求。 客户端还可以通过向Redis发送SAVE命令来创建一个快照，接到SAVE命令的Redis服务器在快照创建完毕之前将不再响应任何其他命令。SAVE命令并不常用，我们通常只会在没有足够内存区执行BGSAVE命令的情况下，又或者即时等待持久化操作执行完毕也无所谓的情况下，才会使用这个命令。 如果用户设置了save配置选项，比如 save 60 10000，那么从Redis最近一次创建快照之后开始算起，当“60秒之内有10000次写入”，这个条件被满足时，Redis就会自动触发BGSAVE命令。如果 用户设置了多个save配置选项，那么当任意一个save配置选项所设置的条件被满足时，Redis就会触发一次BGSAVE命令。 当Redis通过SHUTDOWN命令接收到关闭服务器的请求时，或者接收到标准TERM信号时，会执行一个SAVE命令，阻塞所有的客户端，不在执行客户端发送的任何命令，并在SAVE命令执行完毕之后关闭服务器。 当一个Redis服务器连接另一个Redis服务器，并向对象发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有在执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令。 RDB优缺点 RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份redis中的数据。 RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。 如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。 RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。 AOF持久化概念​ 简单的来说，AOF持久化会将被执行的写命令写到AOF文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾重新执行以此AOF文件包含的所有写命令，就可以恢复AOF文件所记录的数据集。 打开及配置AOF持久化​ AOF持久化可以通过配置appendonly yes配置选项来打开。然后可以通过配置appendfsync配置选项对AOF文件的同步频率。 选项 同步频率 alawys 每个Redis写命令都要同步写入硬盘，这样做会严重降低Redis的速度 everysec 每秒执行一次同步，显式的将多个写命令同步到硬盘 no 让操作系统来决定应该何时进行同步 ​ 一般来说，比较常用的是appendfsync everysec选项，让Redis以每秒一次的频率对AOF文件进行同步。Redis每秒同步一次AOF文件的性能和不使用任何持久化特性时的性能相差无几，而通过每秒同步一次AOF文件，Redis可以保证，即时出现系统崩溃，用户最多丢失一秒之内产生的数据。 AOF的优缺点 AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。 AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。 AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。 AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。 AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低） 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。 RDB和AOF到底该如何选择 不要仅仅使用 RDB，因为那样会导致你丢失很多数据 也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug。 redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。 补充Redis 4.0 混合持久化​ 重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。 ​ 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。 参考书籍《Redis 实战》 参考文件：]]></content>
      <categories>
        <category>Redis 教程</category>
      </categories>
      <tags>
        <tag>微缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis深入学习之实现主从和哨兵]]></title>
    <url>%2F2019%2F01%2F21%2Fredis%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%AE%9E%E7%8E%B0%E4%B8%BB%E5%8A%A8%E5%92%8C%E5%93%A8%E5%85%B5%2F</url>
    <content type="text"><![CDATA[redis主从架构​主从的优势​ 单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 ​ 主从架构除了能够支撑更高的并发量外，还保障了可用性，有了主从，当 master 挂掉的时候，运维让从库过来接管，服务就可以继续，否则 master 需要经过数据恢复和重启的过程，这就可能会拖很长的时间，影响线上业务的持续服务。 redis 配置主从接下来我们通过不同的端口来模拟3台机，实现redis主从 复制redis.conf多分配置文件，并通过端口命名，完成后应该包含三个配置文件 redis-6379.conf redis-6380.conf redis-6381.conf 配置Redis主节点1234port 6381 #指定端口daemonize yes #设置后台启动slave-read-only yes #从节点只读requirepass &quot;123456&quot; #设置密码 配置从节点1234567port 6380\6379 #指定端口daemonize yes #设置后台启动slave-read-only yes #从节点只读requirepass &quot;123456&quot; #设置密码#区别主节点slaveof 127.0.0.1 6381 #配置主节点信息masterauth &quot;123456&quot; #连接主节点配置 配置完主从后，可以启动测试一下 -p 6381 -a 123456 ```连接主节点客户端1234567891011121314输入info能看到当前节点的信息，如果是主节点还可以看到从节点的信息```properties# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6380,state=online,offset=524289,lag=1slave1:ip=127.0.0.1,port=6379,state=online,offset=524289,lag=1master_repl_offset:524555repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:159repl_backlog_histlen:524397 主节点读写都是可以的 1234127.0.0.1:6381&gt; set test 1OK127.0.0.1:6381&gt; keys *1) &quot;test&quot; -p 6379 -a 123456 ```连接从节点客户端123456789输入info能看到当前节点的信息```properties# Replicationrole:slavemaster_host:127.0.0.1master_port:6381master_link_status:up 从节点只能不能写数据 12345127.0.0.1:6380&gt; get test&quot;3&quot;127.0.0.1:6380&gt; set test 2(error) READONLY You can&apos;t write against a read only slave.127.0.0.1:6380&gt; Redis主从实现好了，一旦主节点出现故障，我们可以通过slaveof no one手动将从节点t提升为新的主节点，保障Redis继续正常工作，由于从节前之前同步了数据，所有此时从节点的数据还是和宕机前主节点的数据一致的。 Redis 哨兵sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能： 集群监控：负责监控 redis master 和 slave 进程是否正常工作。 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。 哨兵的优势​ 目前我们讲的 Redis 还只是主从方案，最终一致性。可以实现高并发以及故障转移，但是缺陷就是必须手动切换主节点，首先不能保障任何时候Redis主节点挂了都有人在，其次，主节点挂了，也不能第一时间切换。所以Redis提供了哨兵（Sentinel），自动切换主节点。 配置哨兵​ 配置哨兵只需要修改12345678910111213sentinel-6379.confsentinel-6380.confsentinel-6381.conf配置```sentinel.conf``就不区分主节点和从节点了，统一配置主节点的信息就可以了，他会自动去从主节点找到从节点的信息的```propertiesport 26379\26380\26381 #配置端口sentinel monitor mymaster 127.0.0.1 6381 2 #配置主节点信息 2代表只要有两个从节点任务主节点宕机了，主节点就客观宕机了sentinel auth-pass mymaster 123456 #连接主节点密码 通过sentinel-6379.conf```分别启动三个哨兵,控制台打印如下信息123456```properties18198:X 20 Jan 23:53:43.317 # Sentinel ID is 57e93a8599ad80e26046e70441dbcb83248c832318198:X 20 Jan 23:53:43.317 # +monitor master mymaster 127.0.0.1 6381 quorum 118198:X 20 Jan 23:53:43.317 # +slave slave 127.0.0.1 6379 127.0.0.1 6379 @mymaster127.0.0.1 6381 18198:X 20 Jan 23:53:43.317 # +slave slave 127.0.0.1 6380 127.0.0.1 6380 @mymaster127.0.0.1 6381 此时，我们把6381的Redis人为kill掉，观察控制台，会打印如下信息 1234567891011121314151618198:X 20 Jan 23:55:34.945 # +odown master mymaster 127.0.0.1 6381 #quorum 1/118198:X 20 Jan 23:58:43.681 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 638118198:X 20 Jan 23:58:43.681 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 638118198:X 21 Jan 00:00:14.378 # +new-epoch 218198:X 21 Jan 00:00:14.378 # +try-failover master mymaster 127.0.0.1 638118198:X 21 Jan 00:00:14.383 # +vote-for-leader 57e93a8599ad80e26046e70441dbcb83248c8323 218198:X 21 Jan 00:00:14.383 # +elected-leader master mymaster 127.0.0.1 638118198:X 21 Jan 00:00:14.383 # +failover-state-select-slave master mymaster 127.0.0.1 638118198:X 21 Jan 00:00:14.449 # +selected-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 638018198:X 21 Jan 00:00:14.449 * +failover-state-send-slaveof-noone slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 638018198:X 21 Jan 00:00:14.501 * +failover-state-wait-promotion slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 638018198:X 21 Jan 00:00:15.019 # +promoted-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 638018198:X 21 Jan 00:00:15.019 # +failover-state-reconf-slaves master mymaster 127.0.0.1 638018198:X 21 Jan 00:00:15.114 # +failover-end master mymaster 127.0.0.1 638018198:X 21 Jan 00:00:15.114 # +switch-master mymaster 127.0.0.1 6381 127.0.0.1 638018198:X 21 Jan 00:00:15.115 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6381 mymaster 127.0.0.1 6381 127.0.0.1 6380```从这里可以看到，主节点宕机后，6380从节点自动提升成主节点1234567891011121314151617181920```java18198:X 20 Jan 23:58:43.681 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 637918198:X 21 Jan 00:00:14.378 # +new-epoch 218198:X 21 Jan 00:00:14.378 # +try-failover master mymaster 127.0.0.1 637918198:X 21 Jan 00:00:14.383 # +vote-for-leader 57e93a8599ad80e26046e70441dbcb83248c8323 218198:X 21 Jan 00:00:14.383 # +elected-leader master mymaster 127.0.0.1 637918198:X 21 Jan 00:00:14.383 # +failover-state-select-slave master mymaster 127.0.0.1 637918198:X 21 Jan 00:00:14.449 # +selected-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 637918198:X 21 Jan 00:00:14.449 * +failover-state-send-slaveof-noone slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 637918198:X 21 Jan 00:00:14.501 * +failover-state-wait-promotion slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 637918198:X 21 Jan 00:00:15.019 # +promoted-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 637918198:X 21 Jan 00:00:15.019 # +failover-state-reconf-slaves master mymaster 127.0.0.1 637918198:X 21 Jan 00:00:15.114 # +failover-end master mymaster 127.0.0.1 637918198:X 21 Jan 00:00:15.114 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 638118198:X 21 Jan 00:00:15.115 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 638118198:X 21 Jan 00:00:15.115 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 638118198:X 21 Jan 00:00:45.128 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 638118198:X 21 Jan 00:02:16.242 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 638118198:X 21 Jan 00:02:26.181 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6381 -p 6380 -a 123456 ```连接6380客户端1234567891011```properties# Replicationrole:masterconnected_slaves:1slave1:ip=127.0.0.1,port=6379,state=online,offset=524289,lag=1master_repl_offset:524555repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:159repl_backlog_histlen:524397 可以看到6380此时已经是主节点了，通过sentinel，我们就已经实现了自动切换redis主从节点 其实sentinel实现主节点切换是通过修改Redis配置文件的，此时我们再去查看redis-6380.conf配置文件，就会发现，之前的slaveof 127.0.0.1 6381配置已经不见了，同时redis-6379.conf的配置文件，已经由原先的slaveof 127.0.0.1 6381变成了slaveof 127.0.0.1 6380(在配置文件底部) 总结通过Redis主从和哨兵结合，我们就能在实现Redis并发量增加的同时保障了Redis的可用性，以及出现故障时能够自动实现故障转移。 参考文章]]></content>
      <categories>
        <category>Redis 教程</category>
      </categories>
      <tags>
        <tag>微缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis深入学习之5种基本数据类型]]></title>
    <url>%2F2019%2F01%2F19%2Fredis%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E4%B9%8B5%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Redis 5种基本数据类型前言​ redis平时还是经常使用的，但是只是停留在基本使用上面，5种基本的数据类型基本也只是用了字符串，觉得还是有必要深入学习下Redis，从5种基本数据类型开始。 字符串​ 字符串 string 是 Redis 最简单的数据结构。Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结构的差异就在于 value 的结构不一样。 ​ Redis的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。​ ​ 在Redis里面，字符串可以存储以下3种类型的值。 字符串（byte string） 整数 浮点数 Redis字符串可以对存储的整数或者浮点数字符串执行自增或者自减等操作 命令 用例和描述 INCR INCR key—-将键存储的值加上1 DECR DECR key—-将键存储的值减一 INCRBY INCRBY key amount—-将键存储的值加上整数amount DECRBY DECRBY key amount—-将键存储的值减去整数amount INCRBYFLOAT INCRBYFLOAT key amount—-将键存储的值加上浮点数amount Redis除了自增操作和自减操作之外，还拥有对字符串的其中一部分内容进行读取或者写入的操作 命令 用例和描述 APPEND APPEND key value—-将将值value追加到给定键key-name当前存储的值末尾 GETRANGE INCRBYFLOAT key start end—-获取一个由偏移量start至偏移量end范围内的所有字符组成的子串，包括start和end在内 SETRANGE SETRANGEkey start value—-将从start偏移量开始的子串设置为给定值 GETBIT GETBIT key offset—-将字符串看做是二进制位串，并返回位串中偏移量为offect的二进制位的值 SETBIT SETBIT key offset —-将字符串看做是二进制位串，并将位串中偏移量为offect的二进制位的值设置为value BITCOUNT BITCOUNT key [start end]—-统计二进制字符串里面值为1的数量，可以给定范围，统计范围内1的个数 BITTOP BITTOP operation dest-key key [key]—-对一个或者多个二进制位字符串执行并（and）、或（OR）、异或（XOR）、非（NOT）在内的任意一种按位运算操作，并将计算得出的结果保存在dest-key键里面 列表​ Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。Redis列表允许用户从序列的两端推入或者弹出元素获取元素，以及各种常用的列表操作。 常用的列表处理命令 命令 用例和描述 RPUSH RPUSH key value—-将一个或多个值推入列表的右端 LRUSH LRUSH key value—-将一个或者多个值推入列表的左端 RPOP RPOP key—-移除并返回列表最右端的元素 LPOP LPOP key—-移除并返回列表最左端的元素 LINDEX LINDEX key offset—-返回列表偏移量为offset的元素 LRANGE LRANGE key start end—-返回列表从start偏移量到end偏移量范围内的所有元素。 LTRIM LTRIM key start end—-对列表进行修剪，只保留偏移量start到end之间的元素 Redis列表还可以将元素从一个列表移到另外一个列表，或者阻塞执行命令的客户端直到有其他客户端给列表添加元素为止。 命令 用例和描述 BLPOP BLPOP key timeout—-从第一个非空列表中弹出位于最左端的元素，或者在timeout秒之内阻塞并等待可弹出的元素出现 BRPOP BRPOP key timeout—-从第一个非空列表中弹出位于最右端的元素，或者在timeout秒之内阻塞并等待可弹出的元素 RPOPLPUSH RPOPLPUSH key1 key2 从key1列表中弹出位于最右端的元素，然后将这个元素推入key2列表的最左端，并向用户返回这个元素 BRPOPLPUSH BRPOPLPUSH key1 key2 timeout从key1列表中弹出位于最右端的元素，然后将这个元素推入key2列表的最左端，并向用户返回这个元素；如果key1为空，那么在timeout秒之内阻塞并等待可弹出的元素出现 集合​ Redis的集合以无序的方式来存储多个各不相同的元素，用户可以快速的的集合执行添加元素，移除元素，以及判断一个元素是否存在于集合中。 ​ Java程序员都知道HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。 一些常用集合命令 命令 用例和描述 SADD SADD key item [item]—-将一个或多个元素添加到集合里面，并返回被添加元素当中原本并不存在于集合里面的元素数量 SREM SREM key item [item]—-从集合里面移除一个或者多个元素，并返回被移除的元素数量 SISMEMBER SISMEMBER key item—-检查元素item是否存在于集合key中 SCARD SCARD key—-返回集合包含元素的数量 SMEMBERS SMEMBERS key [count]—-返回集合包含的所有元素 SRANDMEMBER SRANDMEMBER key [count]从集合里面随机的返回一个或者多个元素。当couut为正数时，命令返回的随机元素不会重复；当count为负数时，命令返回的随机元素可能会出现重复 SPOP SPOP key—-随机的移除集合中的一个元素，并返回被移除的元素 SMOVE SMOVE key1 key2 item—-如果key1包含元素item，那么从集合key1里面移除元素，并将元素item添加到集合key2中，如果item被成功的移除，那么命令返回1，否则返回0 集合除了基本的添加，移除元素外，还可以组合和关联多个集合 命令 用例和描述 SDIFF SDIFF key [key]—-返回那些存在于第一个集合，但不存在于其他集合中的元素（差集） SDIFFSTORE SDIFFSTORE key1 key2 [key]—将那些存在于第一个集合但不存在于其他集合中的元素（差集），存储到key1中 SINTER SINTER key [key]—-返回那些同时存在于所有集合中的元素（交集） SINTRTSTORE SINTRTSTORE key1 key2 [key]—将那些同时存在于所有集合中的元素（交集）存储到key1里面 SUNION SUNION key [key]—-返回那些至少存在于一个集合中的元素（并集） SUNIONSTORE SUNIONSTORE key1 key2 [key]—-将那些那些至少存在于一个集合中的元素（并集）存储到key1里面 散列​ Redis的散列可以让用户将多个键值对存储到一个Redis键里面。从功能是来说。Redis为散列值提供了一些与字符串值相同的特性，使得散列非常适用于将一些相关的数据存储在一起。 ​ 哈希等价于Java语言的HashMap或者是Python语言的dict，在实现结构上它使用二维结构，第一维是数组，第二维是链表，hash的内容key和value存放在链表中，数组里存放的是链表的头指针。通过key查找元素时，先计算key的hashcode，然后用hashcode对数组的长度进行取模定位到链表的表头，再对链表进行遍历获取到相应的value值，链表的作用就是用来将产生了「hash碰撞」的元素串起来。Java语言开发者会感到非常熟悉，因为这样的结构和HashMap是没有区别的。哈希的第一维数组的长度也是2^n。 散列的基本命令 命令 用例和描述 HMGET HMGET key -name key [key]—-从散列里面获取一个或者多个键的值 HMSET HMSET key-name key value [key value]—-为散列里面一个或者多个键设置值 HDEL HDEL key-name key [key]—-删除散列里面一个或者多个键值对，返回成功找到并删除的键值对数量 HLEN HLEN key-name—-返回散列包含的键值对数量 其他几个批量操作命令,以及一些和字符串操作类似的散列命令 命令 用例和描述 HEXISTS HEXISTS key-name key—-检查给定键是否存在于散列中 HKEYS HKEYS key-name —-获取散列包含的所有键 HVALS HVALS key-name—-获取散列包含的所有值 HGETALL HGETALLkey-name—-获取散列包含的所有键值对 HINCRBY HINCRBY key-name key increment—-将键key存储的值加上整数increment HINCRBYFLOAT HINCRBYFLOAT key-name key increment—-将键key存储的值加上浮点数increment 有序集合​ 和散列存储着键与值之间的隐射类似，有序集合也存储着成员与分值之间的映射，并且提供了分值处理命令，以及根据分值大小有序的获取或扫描成员和分值的命令。 ​ SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map&lt;String, Double&gt;，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。 一些常用的有序集合命令 命令 用例和描述 ZADD ZADD key socre member [score member]—-将带有给定分支的成员添加到有序集合里面 ZREM ZREM key member [member]—-从有序集合里面移除给定的成员，并返回被移除成员的数量 ZCRD ZCRD key—-返回有序集合包含的成员数量 ZINCRBY ZINCRBY key increment member—-将member成员的分值加上increment ZCOUNT ZCOUNT key min max—-返回分值介于min和max之间的成员数量 ZRANX ZRANX key member—-返回成员member在有序集合中的排名 ZSCORE ZSCORE key member—-返回成员member的分值 ZRANGE ZRANGE key start stop [WITHSCORES]—-返回有序集合中排名介于start和stop之间的成员，如果给定了可选的WITHSCORES选项，那么命令会将成员的分值也一并返回 有序集合的范围型数据获取命令和范围型数据删除命令，以及并集命令和交集命令 命令 用例和描述 ZREVRANK ZREVRANK key member—-返回有序集合里成员member的排名，成员按照分值从大到小排列 ZREVRANGE ZREVRANGE key start stop [WITHSCORES]—-返回有序集合给定排名范围内的成员，成员按照分值从大到小排列 ZRANGEBYSCORE ZRANGEBYSCORE key min max [WITHSCORES] —-返回有序集合中，分值介于min和max之间的成员 ZREVRANGEBYSCORE ZREVRANGEBYSCORE key max min [WITHSCORES]—-获取有序集合中分值排名介于min和max之间的所有成员，并按照分值从大到小的顺序来返回它们 ZREMRANGEBYRANK ZREMRANGEBYRANK key start stop–移除有序集合中分值介于min 和 max之间的所有成员 ZREMRANGEBYSCORE ZREMRANGEBYSCORE key min max—-移除有序集合中分值介于min和max之间的所有成员 ZINTERSTORE ZINTERSTORE key1 key1-count key2 [key]—-对给定的有序集合执行类似集合的交集运算 ZUNIONSTORE ZUNIONSTORE key key-count key [key] 对给定的有序集合执行类似于集合的并集运算]]></content>
      <categories>
        <category>Redis 教程</category>
      </categories>
      <tags>
        <tag>微缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown插入本地图片小技巧]]></title>
    <url>%2F2019%2F01%2F13%2Fmarkdown%E6%8F%92%E5%85%A5%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87%E5%B0%8F%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[markdown插入本地图片小技巧背景​ markdown作为一种普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式，非常的好用，但是插入本地图片很不方便，接下来我们介绍一种非常实用的上传本地图片的方法。 插入本地图片的几种方法以下几种方法参考他人博客，末尾回帖出原文地址 插入本地图片只需要在基础语法的括号中填入图片的位置路径即可，支持绝对路径和相对路径。 例如： ![avatar](本地文件路径) 不灵活不好分享，本地图片的路径更改或丢失都会造成markdown文件调不出图。 插入网络图片只需要在基础语法的括号中填入图片的网络链接即可，现在已经有很多免费/收费图床和方便传图的小工具可选。 例如： ![avatar](网络图片路径) 将图片存在网络服务器上，非常依赖网络。 把图片存入markdown文件用base64转码工具把图片转成一段字符串，然后把字符串填到基础格式中链接的那个位置。 例如： ![avatar][base64str] 使用选型不得不说，上面几种方法，各有优缺点，但是为了方便以及图片能够正常的显示，还是使用网络图片比较靠谱，所以这里介绍一个通过有道云笔记来保存图片，生成网络地址的方法。 使用有道云生成图片网络地址表示博主也刚使用markdown不久，之前就被这个本地图片困扰，用一种方式，在csdn会出现图片不能打开，要重新上传假设此时我们有一个本地图片才能访问，后面使用Hexo搭建个人博客后，这种方式完全行不通了，所以找了一种通过有道云生成图片网络地址方法（图床工具没找到）。 假设我们需要添加到markdown文件中，我们只需要把图片保存到有道云笔记中 然后右键分享图片 查看分享 右键复制图片地址 1https://note.youdao.com/yws/api/personal/file/66294A284E5D4290BC9524515C60F9C9?method=download&amp;shareKey=2ac22444598f8c3eda2c87705881b0ff 将（）中的地址改成网络地址就可以通过网络来访问我们上传的本地图片啦，不过这个图片不能删除哦，删除了网络地址也将不能正常访问了 总结使用有道云把我们需要用到的图片保存起来，通过图片地址就可以实现图片的不限制访问了，是不是很方便。 参考链接简书]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud hystrix服务短路和服务降级]]></title>
    <url>%2F2019%2F01%2F12%2FSpring-Cloud-hystrix%E6%9C%8D%E5%8A%A1%E7%9F%AD%E8%B7%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E9%99%8D%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[Spring Cloud Hystrix实现服务短路和服务降级背景​ 在微服务架构中，我们将系统拆分成了一个个的服务单元，各单元应用间通过服务注册与订阅的方式互相依赖。由于每个单元都在不同的进程中运行，依赖通过远程调用的方式执行，这样就有可能因为网络原因或是依赖服务自身问题出现调用故障或延迟，而这些问题会直接导致调用方的对外服务也出现延迟，若此时调用方的请求不断增加，最后就会出现因等待出现故障的依赖方响应而形成任务积压，线程资源无法释放，最终导致自身服务的瘫痪，进一步甚至出现故障的蔓延最终导致整个系统的瘫痪。如果这样的架构存在如此严重的隐患，那么相较传统架构就更加的不稳定。为了解决这样的问题，因此产生了断路器等一系列的服务保护机制。 断路器和服务降级断路器（服务熔断）​ 很多朋友一开始可能会把断路器和服务降级的概念搞混（表示一开始我也傻傻分不清），这两个其实不是同一个东西来的，断路器本身是一种开关装置，用于在电路上保护线路过载，当线路中有电器发生短路时，断路器能够及时切断故障电路、防止发生过载、发热甚至起火等严重后果。在微服务架构中，断路器的作用也是类似的，当某个服务单元发生故障（类似用电器发生短路）之后，通过断路器的故障监控，向调用方返回一个错误响应，而不是长时间的等待。这样就不会使得线程因服务调用故障服务被长时间占用不释放，避免了故障在分布式系统中的蔓延。 服务降级​ 当某个服务出现故障了，在还没修复之前，请求进来肯定都是出错的，从系统整理负荷考虑，此时我们可以提供一种应急方案，主逻辑出错，此时应急方案（次逻辑）就被当成主逻辑调用，保证系统的正常运行。等服务主逻辑被修复了再切换回主逻辑，切换这个过程，可以人工干预，也可以是通过自动策略实现。降级本身也是一种策略，不仅仅应用在微服务中，在分布式系统架构中，会针对很多场景提供降级方案。这样能更好的保证系统的高可用性。 Spring Cloud断路器和服务降级​ 在Spring Cloud中，断路器和服务降级是相辅相成的，通过Hystrix实现，当服务熔断后，可直接调用回调方法实现服务降级。同时Hystrix会从系统度量指标metrics中获取服务的健康状态，根据请求总数（QPS），错误百分比等信息，来调整断路器超时时间，某段时间内（休眠窗）使得原先需要2s（Hystrix默认超时时间）才能够触发熔断的逻辑不再有超时时间限制，直接调用降级方法（次逻辑）。相当于在一段时间内，当次逻辑当成主逻辑执行，不再执行主逻辑。一段时间后断路器将进入半开状态，释放一次请求到原来的主逻辑上，如果此次请求正常返回，那么断路器将继续闭合，主逻辑恢复，如果这次请求依然有问题，断路器继续进入打开状态，休眠时间窗重新计时。 Hystrix 示例​ 我们首先启动3个工程，服务注册中心、consumer服务、consumer2、这几个工程都是基于前面章节的示例，不记得朋友可以去前面章节查看。 ​ 其中consumer是用来远程掉用consumer2提供的服务，我们给他加上Hystrix功能 添加Hystrix依赖12345 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 博主这里用的spring boot1.5.19，不加版本号，默认去找的Hystrix1.4.7RELEASE版本，pom会报错提示找不到对应版本，跑到maven仓库一看，最高才1.4.6.RELEASE，肯定找不到呀，所以这里指定下版本就好了。 启动类添加@EnableCircuitBreaker注解12345678910111213141516171819@EnableCircuitBreaker@SpringBootApplication@EnableDiscoveryClientpublic class EurekaClientApplication &#123; public static void main(String[] args) &#123;// SpringApplication.run(EurekaClientApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; consumer的HelloService1234567891011121314151617@Servicepublic class HelloServer &#123; @Autowired RestTemplate restTemplate; @HystrixCommand(fallbackMethod = "helloFallback") public String hello()&#123; return restTemplate.getForEntity("http://consumer2/hello",String.class).getBody(); &#125; public String helloFallback()&#123; return "fallback error"; &#125; &#125; HelloService这里主要是用来调用consumer2的hello服务，Hystrix是用于客户端的，所以我们这里开启Hystrix,开启只需要在调用方法上面加上@HystrixCommand注解就可以了，这里我们在指定下fallbackMethod(用于降级的回调方法)为helloFallback。 consumer2的HelloController123456789101112131415@RestControllerpublic class HelloController &#123; private final Logger logger = Logger.getLogger(getClass()); @Autowired private DiscoveryClient client; @RequestMapping(value="/hello",method = RequestMethod.GET) public String index()&#123; ServiceInstance instance = client.getLocalServiceInstance(); logger.info("/hello host:"+instance.getHost()+"server_id"+instance.getServiceId()+"端口："+instance.getPort()); return "hello"; &#125;&#125; HelloController就是consumer2提供的hello服务，这里为了简单测试，就没加服务层了。 测试我们启动注册中心、consumer、consumer2 服务列表 此时能够看到consumer和consumer2实例都正常启动了 访问http://localhost:1112/hello 此时能够看到服务能够正常调用返回hello，接下来我们把consumer2停掉 不启动consumer2服务测试这里我们测试下不启动consumer2用来模拟服务出现故障的情况 服务列表 访问http://localhost:1112/hello 此时能够看到，consumer2出现故障时，能够触发服务熔断并且调用我们指定的回调方法，达到降级的目的。我们再次启动consumer2，此时又能正常的调用，输出hello了。 给consumer添加休眠，模拟网络阻塞我们之前有提到，断路器的默认短路时间为2秒，这里我们给consumer2休眠3秒，看看能不能触发服务熔断 改造consumer2的HelloController类 123456789101112131415161718192021@RestControllerpublic class HelloController &#123; private final Logger logger = Logger.getLogger(getClass()); @Autowired private DiscoveryClient client; @RequestMapping(value="/hello",method = RequestMethod.GET) public String index()&#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; ServiceInstance instance = client.getLocalServiceInstance(); logger.info("/hello host:"+instance.getHost()+"server_id"+instance.getServiceId()+"端口："+instance.getPort()); return "hello"; &#125;&#125; 服务列表 这里两个实例都正常启动了，上面的红色警告是没有关闭Eureka的保护机制提醒的，不影响调用。 访问http://localhost:1112/hello 此时可以看到，即时服务正常启动了，但是超过Hystrix的短路超时时间，也会触发熔断。Hystix的超时时间我们可以通过以下配置指定 1hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=60000 总结通过这篇文章，我们了解了服务熔断，服务降级。以及怎么在Spring Cloud中通过Hystix实现断路器和服务降级。 其实Hystix除了实现断路器和服务降级，还可以用来缓存请求（不能跨请求缓存），请求合并等。。，以后有机会可以单独介绍。]]></content>
      <categories>
        <category>Spring Cloud教程</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo搭建个人博客]]></title>
    <url>%2F2019%2F01%2F07%2F%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[前言​ 2018年终总结就提到要搭建一个个人博客，没想到这么快就完成了，其实使用Hexo+Github搭建博客还是挺方便的，这里记录下搭建过程。 我的博客 (域名还在备案，暂且先通过github地址访问) 搭建HexoHexo是高效的静态站点生成框架，基于Node.js。通过 Hexo 你可以轻松地使用 Markdown 编写文章 安装步骤 安装Git 安装Node.js 安装Hexo 放到github 安装GitGit其实工作中一直在使用，这里就不演示安装过程了，读者可自行下载安装，Window基本都是next next就完事了。 成功安装后，输入 git version,可以显示git版本信息 这里要注意下，Git安装完成后，要配置下全局邮箱和全局用户名 12git config --global user.name "dailingnan"git config --global user.email "250660705@qq.com" 安装Node.js下载地址：http://nodejs.cn/download 安装过程同样不在详细列出了，都是next next完事 安装完成可以通过以来命令测试 12node -vnpm -v npm是安装Node.js的时候就一块安装来的 如果安装没报错，但是不能执行两个命令出现 commod not found一般就是环境变量在作怪，配置下环境变量就好了 安装Hexo安装Hexo利用安装好的npm就可以了 安装前，先设置npm镜像为淘宝镜像 1npm config set registry https://registry.npm.taobao.org 1npm install hexo-cli -g 安装过程中windwos安装可能会出现两个警告，不过不影响安装，是linux的警告 显示图上的信息就是安装成功了 补充：（由于博主已经安装过一次了，不敢卸载重装，到csdn找了几个图，文章末尾会将参考地址贴出来） 接下来输入hexo -v即可测试是否安装成功，出现版本信息就是安装成功了 如果出现commod not found也不必担心没安装好，同样是环境变量在作怪，一般npm安装，就自己配置好了环境变量，不过博主安装没有，自己去配的。 此时，可以先到node.js安装目录，通过cmd 运行 hexo -v来检验，没配环境变量，在这里也是可以执行这个命令的 比如博主的地址：D:\kaifa\nodejs\node_global 接下来我们把这个地址配置到path变量下面就好了，此时执行hexo -v就能正确的出现版本信息了 接下来找一个自己常用的位置执行Hexo的初始化(右键 git bash) 123hexo init hexo npm installhexo g 初始化完成后，能看到生成了一个hexo的文件夹，里面生成了hexo的一些文件 此时执行hexo s启动hexo服务来看一下效果 接下来访问loaclhost:4000，就能看到我们自己的博客了 放到github 新建一个Repository来存放hexo的页面，这里没啥特别的，就是名字一定要注意，必须为用户名.github.io，这样等会才能访问（gitpage访问方式） 接下来配置下hexo目录表的站点配置文件_config.yml 1234deploy: type: git repo: git@github.com:dailingnan/dailingnan.github.io.git branch: master 上面repo的地址就是仓库的地址 接下来我们先确保本地能先连接github，这里不在讲述怎么连接了，读者可自行尝试 连接成功后，输入$ ssh -T git@github.com 出现HI 用户名就可以了 接下来就是把我们本地hexo生成的静态页面放到Github上面了 执行hexo d -g 接下来就可以通过之前配置仓库时候的 用户名.github.io的地址来访我们我们自己的博客了 补充：博主这里是后面修改了hexo的主题，以及增加了一些小功能插件，读者感兴趣的话可以交流哈 后面读者还可以去购买一个域名，绑定自己的博客，之后就能通过自己的域名访问博客了。读者就购买了一个阿里云的域名，现在还在备案中 总结尝试后才发现搭建自己的个人博客还是挺简单的，希望之后能坚持写博客。博客功能也将在后期完善，目前先把csdn的博客迁移过去。]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>个人博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 服务注册和发现]]></title>
    <url>%2F2019%2F01%2F07%2FSpring%20Cloud%20%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%92%8C%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[Spring Cloud 服务注册和发现搭建服务注册中心 导入maven依赖1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.19.BUILD-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.BUILD-SNAPSHOT&lt;/spring-cloud.version&gt; &lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.BUILD-SNAPSHOT&lt;/spring-cloud.version&gt; &lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 可通过Spring Initializr选择Eureka Server模块生成，要注意下SpringBoot的版本，不同的版本对应不同的Spring Cloud版本，我这里用的是1.5.19。 修改配置文件123456server.port=1111eureka.instance.hostname=localhost#关闭向注册中心注册eureka.client.register-with-eureka=false#关闭从注册中心获取实例eureka.client.fetch-registry=false 由于本身就是服务端，所以不需要向注册中心注册自己本身，服务端的只要职责是维护服务实例，所以也不需要获取服务实例 修改启动类123456789@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 导入依赖后，只需要在启动上面加上@EnableEurekaServer注解就可以了 启动直接启动应用，然后访问http://localhost:1111/就能看到注册中心的界面 此时可以看到实例列表是没有实例的，接下来我们注册一个客户端上去 搭建Eureka客户端导入maven依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件1234spring.application.name=consumerserver.port=1112#指定注册中心的地址eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 这里只需要指定注册中心的地址就可以了 修改启动类12345678@SpringBootApplication@EnableDiscoveryClientpublic class EurekaClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientApplication.class, args); &#125;&#125; 这里只需要加上@EnableDiscoveryClient注解就可以了 启动启动Eureka客户端后，我们再次查看注册中心就能发现我们的客户端实例注册上去了 Eureka Server增加安全用户认证在使用Eureka Server的时候，我们直接访问注册中心的页面就能看到所有的实例信息，在生产环境这样肯定是不安全的，不仅如此，我们把Eureka Client注册上去也不需要认证，用户只要知道地址就能达到把自己的服务伪装成同名服务注册上去，这也是很不安全的，Erueka Server对此提供了安全用户认证。 配置访问用户名和密码1234567#添加HTTP basic基本验证security: basic: enabled: true user: name: dailn password: dailn!123 首先我们需要开启安全校验，然后配置用户名和密码 访问注册中心管理页面 可以看到，这里就需要校验用户和密码了，只有校验通过才能访问注册中心管理页面 客户端再次注册1com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server 增加了安全认证后，客户端就注册不上去了，此时我们需要在客户端注册的时候也加上安全认证 123eureka.client.security.basic.user=dailneureka.client.security.basic.password=dailn!123eureka.client.serviceUrl.defaultZone=http://$&#123;eureka.client.security.basic.user&#125;:$&#123;eureka.client.security.basic.password&#125;@localhost:1111/eureka/ 重新启动就能注册成功，在注册中心管理界面也能看到实例了 总结这一篇文章我们简单的学习下服务的注册和发现，只需要导入相关的依赖，修改配置文件和启动类就可以了，最后为了安全起见还给Erureka Server增加了安全认证，下一篇文章在介绍服务端如何实现高可用。]]></content>
      <categories>
        <category>Spring Cloud教程</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 负载均衡]]></title>
    <url>%2F2019%2F01%2F07%2FSpring%20Cloud%20Ribbon%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[Spring Cloud Ribbon实现负载均衡负载均衡负载均衡在系统架构中是一个非常重要的角色，在前面大型网站架构学习总结中，可以看到，高可用，伸缩性，性能几个架构要素中，负载均衡都有着很重要的地位，是系统压力缓解，系统扩容的重要手段之一。 服务端负载一般来说，我们讲的负载均衡都是讲服务端负载均衡（不论硬负载还是软负载），比较常见的通过Nginx反向代理来实现负载均衡，例如下面图中所示 客户端负载均衡这次我们所用到的Ribbon其实就是一种客户端负载均衡，与服务端负载均衡不同的是，客户端负载均衡不是通过一个统一的均衡器（Nginx）去均衡的，而是每一个客户端都维护着各自的负载均衡实现，例如下图所示 优势与不足对比 客户端负载均衡：优势主要体现在稳定性高，各个客户端的负载均衡互不影响，例如上面客户端负载均衡中客户端2的Ribbon出问题了，肯定不会影响客户端1的调用的。劣势就是相对的，升级维护成本高，每次要升级的时候，每个客户端的Ribbon都需要升级。 服务端负载均衡：优势主要体现在统一维护成本低，例如上面的服务端负载均衡，只需要升级Nginx就可以了。劣势同样是相对的，一旦故障，影响大。上面服务端负载均衡中，只要Nginx出问题了，整个系统就不能正常访问了。 Spring Cloud整合Ribbon实现负载均衡新建服务名为consumer2的Eureka Client（两个实例）实例11234server.port=1115spring.application.name=consumer2eureka.instance.hostname=localhost1eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 实例21234server.port=1114spring.application.name=consumer2eureka.instance.hostname=localhost1eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 提供的服务接口1234567891011121314151617@RestControllerpublic class HelloController &#123; private final Logger logger = Logger.getLogger(getClass()); @Autowired private DiscoveryClient client; @RequestMapping(value="/hello",method = RequestMethod.GET) public String index()&#123; ServiceInstance instance = client.getLocalServiceInstance(); logger.info("/hello host:"+instance.getHost()+"server_id"+instance.getServiceId()+"端口："+instance.getPort()); return "hello"; &#125;&#125; consumer2的两个实例已经准备好了，暴露出来的接口，访问会打印出各自对应的端口信息，接下来我们就通过Ribbon来测试负载均衡 新建名为consumer3的Ribbon Erueka Client工程123server.port=1116spring.application.name=consumer3eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ Erueka Client导入Ribbon依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 引入Ribbon123456789101112131415@SpringBootApplication@EnableDiscoveryClientpublic class EurekaRibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaRibbonApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 这里可以看到，就是在之前用到的RestTemplate对象加上@LoadBalanced注解就达到将Ribbon引入的目的了 测试负载均衡接口12345678910111213141516171819@RestControllerpublic class HelloController &#123; private final Logger logger = Logger.getLogger(getClass()); @Autowired private DiscoveryClient client; @Autowired RestTemplate restTemplate; @RequestMapping(&quot;/hello&quot;) public String index()&#123; //在这里调用consumer2提供的接口 return restTemplate.getForEntity(&quot;http://consumer2/hello&quot;,String.class).getBody(); &#125;&#125; 接下来我们分别启动consumer2的两个实例（对应实际中的两台服务器），以及一个包含Ribbon的comsumer3实例。启动完成后服务列表如下 访问http://localhost:1116/hello，我们通过浏览器访问5次 consumer2 （1115）实例控制台输出信息 1232018-12-30 23:00:17.557 INFO 11468 --- [nio-1115-exec-3] c.d.eureka_client1.HelloController : /hello host:localhost1server_idconsumer2端口：11152018-12-30 23:00:22.898 INFO 11468 --- [nio-1115-exec-5] c.d.eureka_client1.HelloController : /hello host:localhost1server_idconsumer2端口：11152018-12-30 23:00:29.584 INFO 11468 --- [nio-1115-exec-7] c.d.eureka_client1.HelloController : /hello host:localhost1server_idconsumer2端口：1115 ​ consumer2 （1114）实例控制台输出信息 122018-12-30 23:00:25.757 INFO 12652 --- [nio-1114-exec-3] c.d.eureka_client1.HelloController : /hello host:localhost1server_idconsumer2端口：11142018-12-30 23:00:30.086 INFO 12652 --- [nio-1114-exec-4] c.d.eureka_client1.HelloController : /hello host:localhost1server_idconsumer2端口：1114 这里可以看到，consumer2 （1115）实例被访问了3次， consumer2 （1114）被访问了2次，由于我们没有配置访问策略，所以默认用的轮询策略，也就证明Ribbon起到负载均衡的作用了。 负载均衡策略这里对上面说的策略补充一下，Ribbon中主要有以下几种策略 随机规则：RandomRule 随机访问一个实例 最可用规则：BestAvailableRule 根据性能，响应速度，空闲程度等计算 轮询规则(Ribbon默认)：RoundRobinRule 多个实例依次轮询访问 重试实现：RetryRule 对内部定义的策略反复尝试 总结Eureka 整合Ribbon后，通过RestTemplate以服务名访问的方式调用就能实现负载均衡，我们不需要关注各应用的ip、端口，这些信息Ribbon都能从Eureka Server的服务列表获取到，在此基础上，实现Ribbon还是挺方便的。 参考书籍《Redis 实战》 参考文章 Redis 基础数据结构]]></content>
      <categories>
        <category>Spring Cloud教程</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 服务端高可用]]></title>
    <url>%2F2019%2F01%2F07%2FSpring%20Cloud%20%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Spring Cloud 服务端高可用背景在上一篇文章中，我们学习了基本的服务注册和发现，在微服务架构这样的分布式环境中，，我们要充分考虑发生故障的情况，我们知道Eureka服务端主要是维护客户端实例，所以高可用尤为重要，不可能说一个服务端挂了，导致所有的客户端都不可用，接下来我们就学习下如何让服务端实现高可用。 高可用注册中心Eureka Server的设计一开始就考虑了高可用的问题，在Eureka的服务治理中，所有服务实例既是服务消费者，也是服务提供者，注册中心也同样如此。之前我们在搭建Eureka Server的时候，有在配置文件中增加 123#不向注册中心注册自己eureka.client.register-with-eureka=falseeureka.client.fetch-registry=false 这里是因为自己本身就是服务提供者，就没必要在这个基础上注册自身了，但是还是可以向其他注册中心以服务的方式注册自己的，这就是Eureka Server实现高可用的方式。 Eureka Server的高可用实际上就是将自己作为服务向其他注册中心注册自己，这样就可以形成一组互相注册的服务注册中心，以实现服务清单的互相同步，达到高可用的效果。 实现高可用两个Eureka Server的配置这里我们在之前的Eureka Server基础上增加一个注册中心，并且相互注册，下面试两个注册中心的配置 第一个Eureka Server配置1234567server.port=1111#设置主机名eureka.instance.hostname=localhosteureka.client.register-with-eureka=falseeureka.client.fetch-registry=false#向Eureka Server 2注册eureka.client.serviceUrl.defaultZone=http://localhost1:1113/eureka/ 第二个Eureka Server配置1234567server.port=1113#设置主机名eureka.instance.hostname=localhost1eureka.client.register-with-eureka=falseeureka.client.fetch-registry=false#向Eureka Server 1注册eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 这里补充下，因为Eureka 是使用主机名注册的，所以我们指定主机名，然后在HOST文件中加上对应关系 12127.0.0.1 localhost127.0.0.1 localhost1 也可以通过指定ip的方式注册 123456789101112131415161718192021222324252627282930313233#### 测试高可用##### 查看各自的注册中心界面接下来我们分别启动两个服务端，查看其注册中心界面访问http://localhost:1111/![1546144811852](https://note.youdao.com/yws/api/personal/file/77CC3862BDC947FA81ABBE109C0449C7?method=download&amp;shareKey=bb9059b8243983535ee5e54f2fa4f4c5)访问http://localhost:1113/![1546144831986](https://note.youdao.com/yws/api/personal/file/83704A6AFE9C44F79E1F72A879D3D451?method=download&amp;shareKey=e754bb77b79d15429a24f64a89f29b86)这里可以看到在**DS Replicas**中，有另外一个注册中心的地址，**DS Replicas**是副本的意思，出现这个就代表成功把自己当做服务注册到另外一个注册中心上面去了。##### 通过客户端来测试高可用我们通过各自的注册中心能够发现副本就代表注册成功了，那么接下来我们就可以通过Eureka Client来测试一波，流程如下1. 开启两个Eureka Server，并且相互注册。2. 开启一个Eureka Client，并且向两个Eureka Server分别注册3. 访问通过**RestTemplate**以服务名的方式能够成功访问客户端自己提供的服务。4. 停止任意一个Eureka Server，再继续访问，看能否成功访问###### Eureka Client配置```propertiesspring.application.name=consumerserver.port=1112#向注册中心注册自己，多个用逗号隔开eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/,http://localhost1:1113/eureka/ 测试Java类1234567891011121314151617181920212223242526/** * @author dailn * @Classname TestController * @Desc * @create 2018-12-30 11:34 **/@RestControllerpublic class TestController &#123; Logger logger = LoggerFactory.getLogger(TestController.class); @Autowired RestTemplate restTemplate; @RequestMapping("/test") public void test()&#123; restTemplate.getForEntity("http://CONSUMER/helloWord",String.class).getBody(); &#125; @RequestMapping("/helloWord") public String helloWord()&#123; logger.info("helloWord"); return "hello word!"; &#125;&#125; 接下来我们再次查看两个注册中心界面 都能看到Eureka Client名为consumer的实例已经注册上来 然后访问测试接口http://localhost:1112/test，观察控制台打印信息 12018-12-30 12:55:24.680 INFO 11084 --- [nio-1112-exec-7] c.d.eureka_client.TestController : helloWord 接下来我们停掉一个服务在观察控制台，为了准确性，我们多访问几次 1232018-12-30 13:00:58.104 INFO 11084 --- [nio-1112-exec-1] c.d.eureka_client.TestController : helloWord2018-12-30 13:01:03.231 INFO 11084 --- [nio-1112-exec-7] c.d.eureka_client.TestController : helloWord2018-12-30 13:01:04.705 INFO 11084 --- [nio-1112-exec-2] c.d.eureka_client.TestController : helloWord 恩，可以看到还是能正常访问，我们切换，停掉另外一个Eureka Server也是同样结果 总结Eureka Server通过注册中心相互注册、同步实例信息、构成集群来实现高可用的，同理，可以推测出Eureka client实现高可用的方式，无非就是改变端口，同一个服务多次注册到注册中心构成集群。客户端集群这里就不在介绍了，等接下来介绍Ribbon的时候在来实现。]]></content>
      <categories>
        <category>Spring Cloud教程</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[啃透Java并发之线程池篇]]></title>
    <url>%2F2019%2F01%2F06%2F%E5%95%83%E9%80%8FJava%E5%B9%B6%E5%8F%91%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%AF%87%2F</url>
    <content type="text"><![CDATA[背景​ Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。 使用线程池的好处 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 线程池的实现原理 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务 线程池的主要成员及关系​ 主要有任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。 他们之间的关系图如下： ThreadPoolExecutor​ ThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建3种类ThreadPoolExecutor：SingleThreadExecutor、FixedThreadPool和CachedThreadPool。 FixedThreadPool。下面是Executors提供的，创建使用固定线程数的FixedThreadPool的API。FixedThreadPool适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 SingleThreadExecutor。下面是Executors提供的，创建使用单个线程的SingleThread-Executor的API。SingleThreadExecutor适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。 CachedThreadPool。下面是Executors提供的，创建一个会根据需要创建新线程的CachedThreadPool的API。CachedThreadPool是大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。 ScheduledThreadPoolExecutor​ ScheduledThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。 ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。 SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。 线程池的使用及源码分析线程池的5中状态123456private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 其中AtomicInteger变量ctl是用来记录线程池状态和数量的：利用低29位表示线程池中线程数，通过高3位表示线程池的运行状态 RUNNING：-1 &lt;&lt; COUNT_BITS，即高3位为111，该状态的线程池会接收新任务，并处理阻塞队列中的任务； SHUTDOWN： 0 &lt;&lt; COUNT_BITS，即高3位为000，该状态的线程池不会接收新任务，但会处理阻塞队列中的任务； STOP ： 1 &lt;&lt; COUNT_BITS，即高3位为001，该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务； TIDYING ： 2 &lt;&lt; COUNT_BITS，即高3位为010, 所有的任务都已经终止； TERMINATED： 3 &lt;&lt; COUNT_BITS，即高3位为011, terminated()方法已经执行完成； 状态之间的转换 线程池的创建123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 创建主要是一些相关参数的初始化，我们来看下这些参数的作用 corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。 maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如果使用了无界的任务队列这个参数就没什么效果。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以，如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。 unit（线程活动保持时间的单位）：可选的单位有天（DAYS）、小时（HOURS）、分钟（MINUTES）、毫秒（MILLISECONDS）、微秒（MICROSECONDS，千分之一毫秒）和纳秒（NANOSECONDS，千分之一微秒）。 workQueue（任务队列）：用于保存等待执行的任务的阻塞队列。可以选择以下几个阻塞队列。 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 PriorityBlockingQueue：一个具有优先级的无限阻塞队列。 threadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。 handler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。在JDK 1.8中Java线程池框架提供了以下4种策略。 AbortPolicy：直接抛出异常。 CallerRunsPolicy：只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 DiscardPolicy：不处理，丢弃掉。 当然，也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。 线程池的执行execute方法123456789101112131415161718192021222324public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //如果工作线程小于corePoolSize，则直接添加线程，添加成功后返回 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //到这里肯定是不能直接添加线程的，核心线程数已达corePoolSize，判断线程处于运行状态， 是否能添加任务至阻塞队列。 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //如果线程池未处于运行状态，将任务从阻塞队列中移除，并执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //如果排队失败（有界的阻塞队列）,说明阻塞队列已满，则添加一个非核心态的worker //如果非核心线程数量达到maximumPoolSize，则执行拒绝策略 else if (!addWorker(command, false)) reject(command); &#125; 添加工作线程addWork方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //线程状态的一些判断，如果线程不是运行状态，返回false // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; /* 数量判断 * 如果当前新增的是核心态的worker则与corePoolSize进行比较 * 如果当期新增的是非核心态的worker则与maximumPoolSize进行比较 * 不满足数量限制则直接添加失败，进入后续的排队或者执行拒绝策略 */ for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //执行到这里，说明满足创建线程的条件，worker数量成功加一，然后进行线程的创建 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; //通过Worker内部类封装任务 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); //添加时再次进行线程池状态检查，线程状态检查 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; //执行任务，调用worker的run方法 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; 从这两段源码，大概能够弄明白线程池执行的原理和流程，创建线程和执行线程。更加详细的内容各位同学可继续详细源码 下面在补充一下未能成功创建线程，但是成功添加至阻塞队列的任务是怎么获取的 getTask123456789101112131415161718192021222324252627282930313233343536373839404142private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? //这里判断基本线程数量是否大于corePoolSize，大于corePoolSize，任务才会被添加到 //阻塞队列 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //主要是在这里从阻塞队列获取任务， //如果有设置超时时间，则调用poll方法获取，超时为空返回false //如果没有设置超时时间，则一直堵塞至有任务可取 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125; &#125; 线程池的关闭 shutdown ：将线程池里的线程状态设置成SHUTDOWN状态, 然后中断所有没有正在执行任务的线程。 shutdownNow ：将线程池里的线程状态设置成STOP状态, 然后停止所有正在执行或暂停任务的线程。 shutdown123456789101112131415161718public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //一些安全检查 checkShutdownAccess(); //设置线程池状态为SHUTDOWN advanceRunState(SHUTDOWN); //通过循环给所有work加上中断标识（t.interrupt()） //这里需要注意，通过interrupt方法来中断线程，能响应的就会中断，无法响应中断的任务 //可能永远无法终止。 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); &#125; shuwdownNow1234567891011121314151617public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(STOP); interruptWorkers(); //和shutdown的主要区别在这里 //shutdown会将阻塞队列中的任务清掉，之后不会继续执行 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks; &#125; 线程池的监控​ 如果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的时候可以使用以下属性。 taskCount：线程池需要执行的任务数量。 completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。 largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。 getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减。 getActiveCount：获取活动的线程数。 总结​ 通过阅读jdk源码，能够更好的理解线程池的实现原理和相关配置（主要是防止cpu资源耗尽或者利用率较低等。。）。也能够在实际中更准确，更有效的使用线程池 参考书籍《java并发编程的艺术》 参考博客：https://www.jianshu.com/p/bf4a9e0b9e60]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[啃透Java并发之内存模型篇]]></title>
    <url>%2F2019%2F01%2F06%2F%E5%95%83%E9%80%8FJava%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Java 内存模型背景​ 在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信。Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 定义​ Java虚拟机规范中试图定义一种Java内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。Java内存模型规定了所有的变量都存储在主内存（Main Memory）中。每条线程还有自己的工作内存（Working Memory），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图所示。 ​ 结合例子来看，如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。 线程A把本地内存A中更新过的共享变量刷新到主内存中去。 线程B到主内存中去读取线程A之前已更新过的共享变量。 内存间交互操作​ 关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外）。 lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 这里需要补充一下java并发常被提起3个特性，原子性，可见性，有序性。 原子性​ 提供了互斥访问，同一时刻只能有一个线程来对他进行操作，由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的，如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。java1.5后concurrent包还提供了一些原子变量类来实现原子性（CAS）。 可见性​ 一个线程对主内存的的修改可以及时的被其他线程观察到，Java语言能实现同步性可见性的有了volatile，synchronized和final。 有序性​ 一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般杂乱无序。Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性。 从上可以看出volatile只能保证可见性和有序性，并不能保证原子性。其中用来保证有序性和可见性的实现也和synchronized存在一定区别，volatile实现可见性和有序性是通过加入内存屏障来实现的，而synchronized则是通过一次控制一个线程执行（串行执行）来实现的，这点要注意区分下。 上面有提到内存屏障和指令重排序，可能有的朋友不了解，下面分别介绍下 内存屏障​ 为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。 指令重排序​ 重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。重排序分3种类型。 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则： 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行过了assign和load操作。 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。 这8种内存访问操作以及上述规则限定，再加上稍后介绍的对volatile的一些特殊规定，就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。由于这种定义相当严谨但又十分烦琐，实践起来很麻烦，java语言中还有一个等效判断原则——先行发生原则（happens-before），他是判断数据是否存在竞争，线程是否安全的主要依据。 happens-before原则 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。 volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。 线程启动规则（Thread Start Rule）：Thread对象的start（）方法先行发生于此线程的每一个动作。 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。 线程中断规则（Thread Interruption Rule）：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 volatile型变量的特殊规则 当一个变量定义为volatile之后，它将具备两种特性，第一是保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成。 使用volatile变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。 这里有一点需要注意：volatile保证可见性并不是说volatile直接操作主内存，volatile同样存在工作内存的拷贝，但是由于其特殊的操作顺序，所以看起来如同直接在主内存读写一般。 总结java内存模型涉及的知识点基本上是这些内容了，好好理解内存模型就能解决经常遇到的各种内存可见性问题。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[啃透Java并发之死锁篇]]></title>
    <url>%2F2019%2F01%2F06%2F%E5%95%83%E9%80%8FJava%E5%B9%B6%E5%8F%91%E4%B9%8B%E6%AD%BB%E9%94%81%E7%AF%87%2F</url>
    <content type="text"><![CDATA[背景​ 在多线程中，我们使用加锁机制来确保线程安全，但如果使用不当，则可能导致死锁。JVM解决死锁问题方面，并不像数据库服务那么强大（数据库系统设计中考虑了检测死锁以及从死锁中恢复），当一组Java线程发生死锁时，”游戏”到此结束，这些线程永远不能再使用了。 死锁的含义​ 当线程A持有锁L并想获得锁M的同时，线程B持有锁M并尝试所得锁L，那么这两个线程将永远的等待下去，这种情况就是最简单的死锁。 死锁产生的四个必要条件 互斥条件：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某 资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。 不剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被 链中下一个进程所请求。 死锁示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.example.demo1.controller; public class LockTest &#123; private final Object left= new Object(); private final Object right = new Object(); public void test() throws InterruptedException &#123; new Thread(()-&gt;&#123; synchronized (left)&#123; try &#123; Thread.sleep(2000); System.out.println("获得left锁"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("持有left锁，请求获取right"); synchronized (right)&#123; System.out.println("获取right成功"); &#125; &#125; System.out.println("left-right解锁完毕"); &#125;).start(); new Thread(()-&gt;&#123; synchronized (right)&#123; try &#123; Thread.sleep(2000); System.out.println("获得right锁"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("持有right锁，请求获取left锁"); synchronized (left)&#123; System.out.println("成功获取left锁"); &#125; &#125; System.out.println("right-left解锁完毕"); &#125;).start(); &#125; public static void main(String[] args) &#123; LockTest lt = new LockTest(); try &#123; lt.test(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 结果： 1234获得right锁持有right锁，请求获取left锁获得left锁持有left锁，请求获取right 以上是一个简单的死锁例子，产生死锁的原因是因为两个线程试图以不同的顺序来获得相同的锁。如果按照相同的顺序来请求锁，那么就不会出现循环的加锁依赖性，因此就不会产生死锁。 死锁一旦发生，在java中就只能中断程序了，所以我们需要在实际中避免死锁的发生。 死锁的避免 加锁顺序：尽量让线程按照顺序加锁。 加锁时限：尝试使用lock.trylock代替内置锁，当然只是在特定的场合（需要使用到定时锁，或者可中断锁的时候），否则应当优先使用内置锁，内置锁1.6优化后内置锁效率接近显示锁。 加锁资源：避免一个线程在锁内同时占有多个资源，尽量保证每个锁只占有一个资源。 加锁数量：避免一个线程同时获取多个锁（上面的例子就是一个线程获取两个锁），有需要时应该尽量缩小锁的范围，能用同步块加锁就不要用同步方法加锁。尽量使用开放调用（在调用某个方法时不需要持有锁，那么这种调用被称为开放调用）。 感兴趣的朋友可以学习下银行家算法（避免死锁发生的著名算法）]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[啃透Java并发之synchronized篇]]></title>
    <url>%2F2019%2F01%2F06%2F%E5%95%83%E9%80%8FJava%E5%B9%B6%E5%8F%91%E4%B9%8Bsynchronized%E7%AF%87%2F</url>
    <content type="text"><![CDATA[场景​ 在多线程并发编程中synchronized一直是元老级角色，作为最基本的互斥手段，很多人都会称呼它为重量级锁。 ​ 但是，随着Java SE 1.6对synchronized进行了各种优化之后，有些情况下它就并不那么重了。Java SE 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 三种形式​ 先来看下利用synchronized实现同步的基础：Java中的每一个对象都可以作为锁。具体表现为以下3种形式。 SE 1.6对synchronized进行了各种优化之后，有些情况下它就并不那么重了。Java SE 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 实现原理​ synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。 ​ monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 ​ 在虚拟机规范对monitorenter和monitorexit的行为描述中，有两点是需要特别注意的。首先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。重入是通过锁的计数器来判断的，如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。 synchronized 1.5与1.6优化后比较​ 在1.5引入重入锁后（ReentratLock），synchronized与之比较尤为显得相对重量级。synchronized在1.5之前是通过阻塞实现同步，每次必须获得锁然后执行操作，执行完毕释放锁。Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 以下是通过跟ReentratLock对比，来体现synchrlnized优化后的效率提升。 java对象头​ synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。具体如下图 java对象头的存取结构 在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据。 自旋锁​ 互斥同步对性能最大的影响是阻塞的实现，在多线程程序中，当线程调度临时挂起活跃线程并转而运行另一个线程时，就会频繁的出现上下文切换操作，这种操作带来极大的开销（挂起线程和恢复线程都需要转入内核态中完成），保存和恢复上下文，丢失局部性，并且cpu时间将更多地花在线程调度而不是线程运行上面。 虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。 ​ 自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX：PreBlockSpin来更改。 自适应自旋锁​ 自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。 偏向锁​ 锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark。 偏向锁的撤销： ​ 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark。 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。 轻量级锁轻量级锁加锁线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 轻量级锁解锁​ Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 补充 轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 轻量级在升级成重量级锁之前会先进行一定的自旋（自适应自旋），自旋拿到锁了就能避免线程上下文切换带来的额外开销。但是在一定次数的自旋还没拿到锁就会升级成重量级锁，后续线程堵塞。直到持有锁的线程释放锁唤醒其他线程，被唤醒的线程开启新的夺锁之争。 锁的优缺点对比 总结​ 看完上面各种锁的区别，现在应该可以理解为什么锁只能升级不能降级了（偏向锁状态可以被重置为无锁状态。），各种锁都有各种锁的应用场景，虽然实际场景中不用我们控制，但是理解synchronized的实现原理，对我们实际的开发也是有很大帮助的。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[啃透Java并发AQS源码分析篇]]></title>
    <url>%2F2019%2F01%2F06%2F%E5%95%83%E9%80%8FJava%E5%B9%B6%E5%8F%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E7%AF%87%2F</url>
    <content type="text"><![CDATA[概念AQS:队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，许多同步器可以通过AQS很容易的并且高效的构建出来。不仅RenntrantLock和Semaphore是基于AQS构建的，还包括CountDownLatch、ReentrantReadWriteLock、SynchronousQueue和FutureTask。 同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。子类推荐被定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。 队列同步器的接口与实例重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。 getState()：获取当前同步状态。 setState(int newState)：设置当前同步状态。 compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。 同步器可重写的方法 protected boolean tryAcquire(int arg):独占式获取同步状态，实现该方法需要查询当前同步状态并判断同步状态是否符合预期，然后在进行CAS设置同步状态 protected boolean tryRelease(int arg):独占式释放同步状态，等待获取同步状态的线程将同步状态有机会获取同步状态 protected int tryAcquireShared(int arg):共享式获取同步状态，返回大于0的值，表示获取成功，反之，获取失败。 protected boolean tryReleaseShared(int arg):共享式释放同步状态 protected boolean isHeldExclusively():当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占。 同步器提供的模板方法 方法名称 描述 void acquire(int arg) 独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将进入同步队列等待，该方法将会调用重写的tryAcquire(int arg) void acquireInterruptibly(int arg) 与acquire(int arg)相同，但是该方法响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，则该方法会抛出InterruptException并返回 boolean tryAcquireNanos(int arg,long nanos) 在acquireInterruptibly的基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，那么将会返回false,如果获取到了返回true void acquireShared(int arg) 共享式的获取同步状态。如果当前线程未获取到同步状态，将会进入同步队列等待，与独占式获取的主要区别是在同一时刻可以有多个线程获取到同步状态 void acquireSharedInterruptibly(int arg) 与acquireShared(int arg)一样，该方法响应中断 boolean tryAcquireSharedNanos(int arg,long nanos) 在acquireSharedInterruptibly的基础上增加了超时限制 boolean release(int arg) 独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒 boolean releaseShared(int arg) 共享式的释放同步状态 Collecion\&lt;Thread> getQueuedThreads() 获取等待在同步队列上的线程集合 同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放同步状态和查询同步队列中的等待线程情况。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义。 下面我们来看一个独占锁实现的例子 1234567891011121314151617181920212223242526272829303132333435363738394041public class Mutex implements Lock &#123; // 静态内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 是否处于占用状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) &#123; if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125;&#125; 由于是实现独占锁，所以我们只需重写独占相关的方法（isHeldExclusively、tryAcquire、tryRelease），独占锁主要需要维护当前的status，基于AQS的模板方法，使得我们方便的实现独占锁。 我们可以稍微来看下AQS相关实现源码 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 123456789101112131415161718192021222324final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; //死循环获取同步状态 for (;;) &#123; final Node p = node.predecessor(); //当节点为头节点时，才尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //非头节点线程进入等待头结点执行完成后唤醒 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 1234567891011121314151617private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; //将当前节点CAS的方式设置为尾节点 if (compareAndSetTail(pred, node)) &#123; //将之前的尾节点的后继节点设置为当前节点 pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; 12345678910111213141516private Node enq(final Node node) &#123; //将当前节点设置为尾节点 for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 12345678910public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒等待的节点 unparkSuccessor(h); return true; &#125; return false; &#125; ​ 上面的代码首先调用我们重写的tryAcquire获取同步状态，获取失败则构造同步节点（Node.EXCLUSIVE代表节点为独占类型），并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现（这里补充说明下，同步队列中通过Node表示当前线程，Node有前驱节点，后继节点）。 通过上面一些列代码，应该不难看出独占锁的实现原理，主要还是通过AQS的状态属性来判断是否加锁以及释放锁，这里稍微对其他的同步组件利用state的方式简单说明 ​ AQS负责管理同步器类中的状态，他管理了一个整数状态信息，可以通过getState，setState，以及compareAndSetState等方法进行操作，这个整数可以用于表示任意状态。例如，ReentrantLock用它来表示所有的者线程已经重复获取该锁的次数，Semaphore用它来表示剩余的许可数量，FutureTask用它来表示任务的状态（尚未开始、正在运行、已完成、以及已取消）。在同步器类中还可以自行管理一些额外的状态变量，例如，ReentrantLock保存了当前所有者（当前线程）的信息，这样就能区分某个获取操作是重入还是竞争。 下面用共享的方式理解下上面话语的含义 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; 12345678910111213141516171819202122232425262728private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); //这里区别于独占锁对state的利用方式 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 总结从上面源码及例子可以看出，其他各种基于AQS的同步组件，主要对state状态利用的方式不同，基础模板方式都是利用AQS自己的实现。通过AQS的源码实现，应该就能很好的理解JUC工具包下面的一些工具类的实现原理了，这里不在继续研究了，有兴趣的朋友可以自行查看源码（RenntrantLock、Semaphore、CountDownLatch等） 参考书籍《java并发编程的艺术》《java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[啃透Java并发之原子操作类(AtomicLong源码分析)和非阻塞算法篇]]></title>
    <url>%2F2019%2F01%2F06%2F%E5%95%83%E9%80%8FJava%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB-AtomicLong%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%92%8C%E9%9D%9E%E9%98%BB%E5%A1%9E%E7%AE%97%E6%B3%95%E7%AF%87%2F</url>
    <content type="text"><![CDATA[背景​ 近年来，在并发算法领域的大多数研究都侧重于非阻塞算法，这种算法用底层的原子机器指令（例如比较并发交换指令）代替锁来确保数据在并发访问中的一致性。非阻塞算法被广泛的用于在操作系统和JVM中实现线程/进程调度机制、垃圾回收机制以及锁和其他并发数据结构。 ​ 与基于锁的方案相比，非阻塞算法在设计和实现上都要复杂的多，但他们在可伸缩性和活跃性上却拥有巨大的优势，由于非阻塞算法可以使多个线程在竞争相同数据时不会发生阻塞，因此它能在粒度更细的层次上面进行协调，并且极大的减少调度开销。锁虽然Java语言锁定语法比较简洁，但JVM操作和管理锁时，需要完成的工作缺并不简单，在实现锁定时需要遍历JVM中一条复杂的代码路径，并可能导致操作系统级的锁定、线程挂起以及上下文切换等操作。 非阻塞算法​ 在基于锁的算法中可能会发生各种活跃性故障，如果线程在持有锁时由于阻塞I/O，内存页缺失或其他延迟执行，那么很可能所有线程都不能继续执行下去。如果在某种算法中，一个线程的失败或挂起不会导致其他线程也失败或挂起，那么这种算法就称为非阻塞算法。如果在算法的每个步骤中都存在某个线程能够执行下去，那么这种算法也被称为无锁算法。如果在算法中仅将CAS用于协调线程之间的操作，并且能够正确的实现，那么他既是一种无阻塞算法，又是一种无锁算法。 ​ Java对非阻塞算法的支持：从Java5.0开始，底层可以使用原子变量类（例如AtomicInteger和AtoMicReference）来构建高效的非阻塞算法，底层实现采用的是一个比较并交换指令（CAS）。 比较并交换（CAS）​ CAS包括了三个操作数，需要读写的内存位置V，进行比较的值A和拟写入的新值B。当且仅当V的值等于A时，CAS才会通过原子方式用新值B来更新A的值，否则不会执行任何操作。无论V的值是否等于A，都将返回V原有的值。CAS的含义是：我认为V的值应该是A，如果是那么将V的值更新为B，否则不修改并告诉V的值实际为多少。 原子变量类​ 原子变量（对应内存模型中的原子性）比锁的粒度更细。量级更轻，并且对于在多处理器系统上实现高性能的并发代码来说是非常关键的。原子变量将发生竞争的范围缩小到单个变量上面，这是你获得的粒度最细的情况。更新原子变量的快速（非竞争）路径不会被获得锁的快速路径慢，并且通常会更快，而它的慢速路径肯定比锁的慢速路径块，因为他不需要挂起或者重新调度线程。在使用基于原子变量而非锁的算法中，线程在执行时更不易出现延迟，并且如果遇到竞争，也更容易恢复过来。 Java中的13个原子操作类​ Java从JDK1.5开始提供了java.util.concurrent.atomic包（以下简称Atomic包），这个包中的原子操作类提供了一种用法简单、性能高效、线程安全地更新一个变量的方式。因为变量的类型有很多种，所以在Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。Atomic包里的类基本都是使用Unsafe实现的包装类。 原子更新基本类型类：使用原子的方式更新基本类型，Atomic包提供了以下3个类。 AtomicBoolean：原子更新布尔类型。 AtomicInteger：原子更新整型。 AtomicLong：原子更新长整型。 原子更新数组：通过原子的方式更新数组里的某个元素，Atomic包提供了以下4个类。 AtomicIntegerArray：原子更新整型数组里的元素。 AtomicLongArray：原子更新长整型数组里的元素。 AtomicReferenceArray：原子更新引用类型数组里的元素。 原子更新引用类型：原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。 AtomicReference：原子更新引用类型。 AtomicReferenceFieldUpdater：原子更新引用类型里的字段。 AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference（V initialRef，boolean initialMark）。 原子更新字段类：如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。 AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。 AtomicLongFieldUpdater：原子更新长整型字段的更新器。 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题。 AtomicLong源码分析​ 上面的4种原子类型都是基于CAS实现，低层借助于unsafe实现原子操作。接下来结合源码，看一下比较有代表性的AtomicLong源码. 初始化12345678910111213141516//保存AtomicLong的实际值，用volatile 修饰保证可见性private volatile long value; // 获取value的内存地址的逻辑操作 static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicLong.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; //根据传入的参数初始化实际值，默认值为0public AtomicLong(long initialValue) &#123; value = initialValue; &#125; 主要更新方法12345678910111213141516171819202122232425//以原子方式更新值为传入的newValue，并返回更新之前的值public final long getAndSet(long newValue) &#123; return unsafe.getAndSetLong(this, valueOffset, newValue); &#125; //输入期望值和更新值，如果输入的值等于预期值，则以原子方式更新该值为输入的值public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update); &#125; //返回当前值原子加1后的值public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L); &#125; //返回当前值原子减1后的值public final long getAndDecrement() &#123; return unsafe.getAndAddLong(this, valueOffset, -1L); &#125; //返回当前值原子增加delta后的值public final long getAndAdd(long delta) &#123; return unsafe.getAndAddLong(this, valueOffset, delta); &#125; unsafe.getAndAddLong123456789101112131415161718192021222324 public native long getLongVolatile(Object var1, long var2); public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); /*unsafe.getAndAddLong(this, valueOffset, 1L)var1 当前值var2 value值在AtomicLong对象中的内存偏移地址*/ public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; //根据var1和var2得出当前变量的值，以便接下来执行更新操作 var6 = this.getLongVolatile(var1, var2); //如果当前值为var6，则将值加var4，这样做是确保每次更新时，变量的值是没有被其他线//程修改过的值，如果被修改，则重新获取最新值更新，直到更新成功 &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6; &#125; 从源码可以看出，获取当前值getLongVolatile方法，比较并交换compareAndSwapLong方法都是native方法。说明不是采用java实现原子操作的，具体各位同学可以继续去查看底层源码（应该是c++）实现，这里不在深入了（能力有限）。 比较并交换的缺陷 通过源码可以看出，原子更新时，会先获取当前值，确保当前值没被修改过后在进行更新操作，这也意味着如果竞争十分激烈，CAS的效率是有可能比锁更低的（一般在实际中不会出现这种情况），JDK后面推出了LongAdd，粒度更小，竞争也会被分散到更低，具体实现各位同学可以自行了解。 ABA是谈到CAS不可避免的话题，比较并交换，会存在这样一个场景，当变量为值A时，将值执行更新。然而在实际中，有可能其他线程将值先改为B，然后又将值改回A，此时还是能够成功执行更新操作的（对于某些不在乎过程的没啥影响，对于链表之类的就不满足了）。解决方式是给变量打上版本号，如果版本号和值一致才执行更新操作（可使用AtomicStampedReference）。 总结非阻塞算法通过底层的并发原语（例如比较交换而不是锁）来维持线程的安全性。这些底层的原语通过原子变量类向外公开，这些类也用做一种“更好的volatile变量”，从而为整数和对象引用提供原子的更新操作。 参考书籍： 《JAVA并发编程实战》 《JAVA并发编程的艺术》]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之观察者模式]]></title>
    <url>%2F2019%2F01%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言​ 观察者模式用简单通俗的说法解释：观察者模式=出版者+订阅者 标准定义​ 观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 通常在观察者模式中有两个角色，主题和观察者，主题和观察者之间的关系如下： 主题：使用此接口注册为观察者，或者把自己从观察者中移除。 具体主题：实现主题接口，除了注册和撤销方法，还是先通知的方法，此方法用于状态更新时通知所有的观察者 观察者接口：该接口只有一个update方法，当主题状态发生改变时会被调用。 具体观察者：实现观察者接口，必须注册具体主题，以便主题更新时得到通知 示例下面我们以一个商场微信公众号的例子演示观察者模式 具体类图如下： 推数据模式Subject 主题接口 123456789101112public interface Subject &#123; //注册观察者 public void registerObserver(Observer observer ); //移除观察者 public void removeObserver(Observer observer); //通知所有观察者 public void notifyObservers(); &#125; Store 商场微信公众号，充当主题实现者，该商场每天会发布打折信息等。。。通过该公众号给消费者推送消息。 12345678910111213141516171819202122232425262728293031323334public class Store implements Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(10); //该商场打折活动消息 private String message; @Override public void registerObserver(Observer observer) &#123; observers.add(observer); &#125; @Override public void removeObserver(Observer observer) &#123; int i = observers.indexOf(observer); if(i&gt;=0)&#123; observers.remove(i); &#125; &#125; @Override public void notifyObservers() &#123; for(Observer observer : observers)&#123; System.out.println("超市发布打折通知："+message); observer.update(message); &#125; &#125; public void updateMessage(String message)&#123; this.message = message; notifyObservers(); &#125; &#125; Observer 观察者接口 123456public interface Observer &#123; //主题发生改变时，观察者调用的方法 public void update(String messgae); &#125; Consumer 消费者，充当观察者实现类，订阅商场公众号，一旦商场公众号发布新的打折信息等。。，消费者能够即时收到通知。 123456public class Consumer implements Observer &#123; @Override public void update(String messgae) &#123; System.out.println("消费者收到通知:"+messgae); &#125;&#125; 现在基本的观察者模式就已经实现了，我们来测试一下 123456public static void main(String[] args) &#123; Store store = new Store(); Observer consumer = new Consumer(); store.registerObserver(consumer); store.updateMessage("今天商场有****商品打折，速速抢购"); &#125; 控制台打印信息： 12超市发布打折通知：今天商场有****商品打折，速速抢购消费者收到通知今天商场有****商品打折，速速抢购 此时可以发现，我们的目的达到了，商场发布信息，消费者只要订阅了改公众号，就能即时收到通知。 以上就是最基础的观察者模式。其实观察者模式有两种从订阅主题获取信息的方式 推送数据：由订阅主题主动推送数据，不在乎观察者是否需要该条数据，统一给全部订阅该主题的消费者推送。 拉取数据：订阅主题信息发生改变时，通知观察者，由观察者主动获取自己需要的数据。 推送数据有一个缺陷主题就是无法针对具体的观察者推送不同数据，而拉取数据相当于把决定权转交给了观察者，主题可以发布所有数据，但是观察者可以根据自己实际需要获取自己想要的数据，拉取数据主题通常会把自己传递给观察者，观察者通过主题对象公开方法（例：get方法）获取自身想要的数据。 很明显，我们刚刚上面实现的是推数据的一种模式，若此时消费者还想观察某一款商品的价格，在低于某一个价格时，消费者能够即时得到通知。 下面我们继续通过拉数据的模式进行改造 拉数据模式Subject 主题，主题没有发生改变 123456789101112public interface Subject &#123; //注册观察者 public void registerObserver(Observer observer ); //移除观察者 public void removeObserver(Observer observer); //通知所有观察者 public void notifyObservers(); &#125; Store 商场公众号，我们在公众号中增加一款牛奶价格属性，同时通知方法中，把自身传递给观察者。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Store implements Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(10); //该商场打折活动消息 private String message="暂无打折商品"; //纯牛奶价格 private int milkPrice = 50; @Override public void registerObserver(Observer observer) &#123; observers.add(observer); &#125; @Override public void removeObserver(Observer observer) &#123; int i = observers.indexOf(observer); if(i&gt;=0)&#123; observers.remove(i); &#125; &#125; @Override public void notifyObservers() &#123; for(Observer observer : observers)&#123; System.out.println("超市发布打折通知："+message); observer.update(this); &#125; &#125; public void updateMessage(String message)&#123; this.message = message; notifyObservers(); &#125; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; public int getMilkPrice() &#123; return milkPrice; &#125; public void setMilkPrice(int milkPrice) &#123; this.milkPrice = milkPrice; notifyObservers(); &#125;&#125; Observer 观察者，观察者的更新方法相应改变，参数不在是具体的属性，而是主题对象 123456public interface Observer &#123; //主题发生改变时，观察者调用的方法 public void update(Subject subject); &#125; Consumer 消费者，当牛奶价格低于45时，能够即时得到通知 12345678910public class Consumer implements Observer &#123; @Override public void update(Subject subject) &#123; Store store = (Store) subject; int price = store.getMilkPrice(); if(price&lt;45)&#123; System.out.println("牛奶最新价格"+price+",速速抢购吧！"); &#125; &#125;&#125; 接下来测试一下 123456public static void main(String[] args) &#123; Store store = new Store(); Observer consumer = new Consumer(); store.registerObserver(consumer); store.setMilkPrice(40); &#125; 控制台： 12超市发布打折通知：暂无打折商品牛奶最新价格40,速速抢购吧！ 恩，此时主题能灵活的应对各个消费者不同的需求，消费者也能够根据自身需要订阅不同的消息。我们也通过这个例子演示了拉取数据模式。 总结观察者模式：一个新的模式，以松耦合的方式在一系列对象之间沟通状态。 参考书籍《Head First设计模式》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之策略模式]]></title>
    <url>%2F2019%2F01%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言​ 一直没有养成写博客的习惯，很早就打算通过设计模式来开始博客之旅，后面因为上半年找工作对并发知识缺乏。就学了一阵子以并发相关内容开始写博客了，现在才写了几篇，之后会继续完善。现在在阅读《Head First设计模式》，刚好博客记录下学习过程。都知道设计模式在OO编程中很重要，理解和在实际中运用完全不是同一回事，但是在运用之前我们起码的先学会不是吗？ 定义​ 策略模式定义了算法族，分别封装起来，让他们之间可以相互替换，此模式让算法的变化独立于使用算法的客户。 使用场景​ 针对同一类型问题的多种处理方式，仅仅是具体行为有差别时，策略模式能够很好地应对变化； 示例​ 下面我们将通过一个烹饪鸡的例子来更好的理解（至于为什么是烹饪鸡，你懂得）； 正常实现首先我们定义一个Person接口类 这个person有很多技能（吃饭睡觉打豆豆），我们不关注，本场景下我们用到的只有一个cookieChicken(烹饪鸡肉) 12345//人物类public interface Person &#123; //烹饪鸡肉 void cookingChicken();&#125; 接下来本篇博客主角陈师傅登场 1234567//陈师傅public class MasterChen implements Person &#123; @Override public void cookingChicken() &#123; System.out.println("辣子鸡"); &#125;&#125; 陈师傅（也喜欢吃鸡肉），尤其是辣子鸡，所以他烹饪鸡的做法，第一种就学的辣子鸡 好，接下来我们把鸡肉交给陈师傅 1234public static void main(String[] args) &#123; Person masterChen = new MasterChen(); masterChen.cookingChicken(); &#125; 天天吃一种菜总是会腻的，尽管喜欢吃，陈师傅依稀记得在重庆旅游的时候，吃过一次正宗的重庆鸡公煲，味道很是美味，话不多话，就是干。陈师傅开始学重庆鸡公煲的做法，不久后出师。 现在我们构造的陈师傅应该怎么样适应变化呢？恩 一开始肯定都是这么想的，我们改造下 12345//人物类public interface Person &#123; //烹饪鸡肉 void cookingChicken(String type);&#125; 人物类中烹饪鸡肉我们增加一个type区分不同的做法 123456789101112//陈师傅public class MasterChen implements Person &#123; @Override public void cookingChicken(String type) &#123; if(type.equals("辣子鸡"))&#123; System.out.println("辣子鸡"); &#125;else if(type.equals("重庆鸡公煲"))&#123; System.out.println("重庆鸡公煲"); &#125; &#125;&#125; 现在的陈师傅可以通过type，来用不同的烹饪方式烹饪鸡肉 12345public static void main(String[] args) &#123; Person masterChen = new MasterChen(); masterChen.cookingChicken("辣子鸡"); masterChen.cookingChicken("重庆鸡公煲"); &#125; 恩，这样我们的目的的确达到了，偶然的一次机会，陈师傅到广州沟通学习，并学会了白切鸡的做法。 为了适应变化，我们又要修改我们构造的陈师傅。不过在修改之前，我们思考一个问题，每次陈师傅新学一种烹饪鸡肉的做法，我们就要修改我们构造的陈师傅，这是不是不合适呢?在OO编程中，我们一直主张对扩展开发，对修改关闭。我们此刻的做法就违背这个原则。在实际生产中我们应该也是尽量做到新增功能不影响原有的功能。 此刻，策略模式隆重登场，在这个场景中，不断变化的是烹饪鸡的做法，我们可以把其看做策略模型中的算法抽离出来。以后增加算法都不影响原有的功能。 策略模式登场类图 改造人物类改造 12345678910public abstract class Person &#123; //烹饪鸡肉的行为 CookChicken cookChicken = null; //烹饪鸡肉 abstract void cookingChicken(); public void setCookChicken(CookChicken oneCookChicken)&#123; cookChicken =oneCookChicken; &#125;&#125; 这里我们将人物类由接口改成了抽象类，将烹饪鸡肉这一做法抽离成行为的方式（面对接口编程不一定是指完全面对Interface编程，关键在于多态。利用多态，程序可以针对超类型编程，某些场景下抽象类比接口更合适） 烹饪鸡肉行为类 123public interface CookChicken &#123; void cooking();&#125; 同时，针对辣子鸡，和白切鸡我们定义了两个实现类 辣子鸡： 123456public class SpicyChicken implements CookChicken &#123; @Override public void cooking() &#123; System.out.println("辣子鸡"); &#125;&#125; 白切鸡： 123456public class WhiteCutChicken implements CookChicken &#123; @Override public void cooking() &#123; System.out.println("白切鸡"); &#125;&#125; 重庆鸡公煲： 123456public class ChongqingChicken implements CookChicken &#123; @Override public void cooking() &#123; System.out.println("重庆鸡公煲"); &#125;&#125; 最后就是经过改造的陈师傅，此刻的陈师傅能够灵活运用多种烹饪鸡肉的做法 123456789101112public class MasterChen extends Person &#123; public MasterChen() &#123; cookChicken = new SpicyChicken(); &#125; @Override public void cookingChicken() &#123; //默认用陈师傅最熟悉的辣子鸡来实例化 cookChicken.cooking(); &#125;&#125; 1234567891011public class Test &#123; public static void main(String[] args) &#123; Person masterChen = new MasterChen(); masterChen.cookingChicken(); masterChen.setCookChicken(new ChongqingChicken()); masterChen.cookingChicken(); masterChen.setCookChicken(new WhiteCutChicken()); masterChen.cookingChicken(); &#125;&#125; 结果如下 123辣子鸡重庆鸡公煲白切鸡 经过我们的改造，我们能在运行时通过setCookChicken在陈师傅工作期间，动态用不同的烹饪手法，做出不同的鸡肉（辣子鸡、重庆鸡公煲、白切鸡）。今后即时陈师傅各种深造，学习更多地烹饪鸡肉的做法。我们也只需要实现更多地烹饪行为实现类，无需对陈师傅进行各种改造。 这就是策略模式，通过将某些相同系列算法抽离程序，在组合进去，使得系统更具有弹性。 总结最后我们在回顾一次策略模式的定义，是不是理解更深刻了呢 策略模式定义：定义了算法族，分别封装起来，让他们之间可以相互替换，此模式让算法的变化独立于使用算法的客户。 参考资料：《Head First 设计模式》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java构建对象实用技巧之Builder模式]]></title>
    <url>%2F2019%2F01%2F05%2FJava%E6%9E%84%E5%BB%BA%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E4%B9%8BBuilder%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[背景在实际中，我们经常遇到这种场景。在实例化一些JavaBean的时候，需要给很多属性赋值。我们通常的做法是给必要的属性一个一个通过set方法赋值。 实践例如 有这样一个用户对象 1234567891011121314151617181920212223242526272829303132333435363738public class UserBean &#123; private String name; private int age; private String sex; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; @Override public String toString() &#123; return "UserBean&#123;" + "name='" + name + '\'' + ", age=" + age + ", sex='" + sex + '\'' + '&#125;'; &#125;&#125; 接下来我们实例化 12345678910public class Test &#123; public static void main(String[] args) &#123; UserBean userBean = new UserBean(); userBean.setName("戴岭南"); userBean.setAge(23); userBean.setSex("男"); System.out.println( userBean.toString()); &#125;&#125; 1UserBean&#123;name='戴岭南', age=23, sex='男'&#125; 恩，这样不是很正常吗，完全没有任何的不适当。 接下来我们增加一些其他相关参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129 public class UserBean &#123; private String name; private int age; private String sex; private String idCard; private int weight; private int height; private String address; private String education; private String birthday; private String post; private String marriage; private String degree; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public String getIdCard() &#123; return idCard; &#125; public void setIdCard(String idCard) &#123; this.idCard = idCard; &#125; public int getWeight() &#123; return weight; &#125; public void setWeight(int weight) &#123; this.weight = weight; &#125; public int getHeight() &#123; return height; &#125; public void setHeight(int height) &#123; this.height = height; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public String getEducation() &#123; return education; &#125; public void setEducation(String education) &#123; this.education = education; &#125; public String getBirthday() &#123; return birthday; &#125; public void setBirthday(String birthday) &#123; this.birthday = birthday; &#125; public String getPost() &#123; return post; &#125; public void setPost(String post) &#123; this.post = post; &#125; public String getMarriage() &#123; return marriage; &#125; public void setMarriage(String marriage) &#123; this.marriage = marriage; &#125; public String getDegree() &#123; return degree; &#125; public void setDegree(String degree) &#123; this.degree = degree; &#125; @Override public String toString() &#123; return "UserBean&#123;" + "name='" + name + '\'' + ", age=" + age + ", sex='" + sex + '\'' + ", idCard='" + idCard + '\'' + ", weight=" + weight + ", height=" + height + ", address='" + address + '\'' + ", education='" + education + '\'' + ", birthday='" + birthday + '\'' + ", post='" + post + '\'' + ", marriage='" + marriage + '\'' + ", degree='" + degree + '\'' + '&#125;'; &#125;&#125; 继续按照set方式对对象进行实例化 12345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; UserBean userBean = new UserBean(); userBean.setName("戴岭南"); userBean.setAge(23); userBean.setSex("男"); userBean.setAddress("湖南省岳阳市"); userBean.setBirthday("19950827"); userBean.setEducation("蓝翔毕业"); userBean.setDegree("学士"); userBean.setHeight(175); userBean.setIdCard("430626***"); userBean.setMarriage("未婚"); userBean.setPost("Java攻城狮"); userBean.setWeight(120); System.out.println( userBean.toString()); &#125;&#125; 1UserBean&#123;name='戴岭南', age=23, sex='男', idCard='430626***', weight=120, height=175, address='湖南省岳阳市', education='蓝翔毕业', birthday='19950827', post='Java攻城狮', marriage='未婚', degree='学士'&#125; 恩，现在看是不是有点。。。。，实例化一个对象就这么大一段代码了。十分的不美观，这里也可以采用构造函数实例化，不过构造函数对参数限制性大，灵活性不高。假如每一个参数都不是必须的，那么我们就要重载对应参数个数个构造函数，更加不灵活。 接下来我们采用Builder模式来改造一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.dailingnan.build; /** * @author dailn * @Classname UserBean * @Desc * @create 2018-12-15 9:41 **/public class UserBean &#123; private String name; private int age; private String sex; private String idCard; private int weight; private int height; private String address; private String education; private String birthday; private String post; private String marriage; private String degree; public static class Build&#123; private String name; private int age; private String sex; private String idCard; private int weight; private int height; private String address; private String education; private String birthday; private String post; private String marriage; private String degree; public Build name(String name)&#123; this.name=name; return this; &#125; public Build sex(String sex)&#123; this.sex=sex; return this; &#125; public Build age(int age)&#123; this.age=age; return this; &#125; public Build idCard(String idCard)&#123; this.idCard=idCard; return this; &#125; public Build weight(int weight)&#123; this.weight=weight; return this; &#125; public Build height(int height)&#123; this.height=height; return this; &#125; public Build address(String address)&#123; this.address=address; return this; &#125; public Build education(String education)&#123; this.education=education; return this; &#125; public Build post(String post)&#123; this.post=post; return this; &#125; public Build marriage(String marriage)&#123; this.marriage=marriage; return this; &#125; public Build birthday(String birthday)&#123; this.birthday=birthday; return this; &#125; public Build degree(String degree)&#123; this.degree=degree; return this; &#125; public UserBean build()&#123; return new UserBean(this); &#125; &#125; private UserBean(Build build) &#123; this.name=build.name; this.age=build.age; this.sex=build.sex; this.idCard=build.idCard; this.weight=build.weight; this.height=build.height; this.address=build.address; this.education=build.education; this.birthday=build.birthday; this.post=build.post; this.marriage=build.marriage; this.degree=build.degree; &#125; @Override public String toString() &#123; return "UserBean&#123;" + "name='" + name + '\'' + ", age=" + age + ", sex='" + sex + '\'' + ", idCard='" + idCard + '\'' + ", weight=" + weight + ", height=" + height + ", address='" + address + '\'' + ", education='" + education + '\'' + ", birthday='" + birthday + '\'' + ", post='" + post + '\'' + ", marriage='" + marriage + '\'' + ", degree='" + degree + '\'' + '&#125;'; &#125;&#125; 采用Builder构建对象 123456789public class Test &#123; public static void main(String[] args) &#123; UserBean userBean =new UserBean.Build().name("戴岭南").age(23).sex("男").post("Java攻城狮") .address("湖南省岳阳市").education("蓝翔毕业").birthday("19950827").weight(120) .degree("学士").height(175).idCard("430626***").marriage("未婚").build(); System.out.println( userBean.toString()); &#125;&#125; 1UserBean&#123;name='戴岭南', age=23, sex='男', idCard='430626***', weight=120, height=175, address='湖南省岳阳市', education='蓝翔毕业', birthday='19950827', post='Java攻城狮', marriage='未婚', degree='学士'&#125; 这种方式创建对象是不是很简捷。 总结​ Builder模式的确有它自身的不足。为了创建对象，必须先创建它的构建器。虽然创建构建器的开销在实践中可能不那么明显，但是在某些十分注重性能的情况下，可能就成问题了。Builder模式还比重叠构造器模式更加冗长，因此它只有在很多参数的时候才使用，比如四个或者更多个参数。 补充：后期通过lombok插件只需要一个注解就可实现build模式哦！ 参考书籍《effective in java》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
</search>
